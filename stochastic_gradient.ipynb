{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1usGlate8wEgOLqJhT1EP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jmanav/from_scratch/blob/main/stochastic_gradient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "whats the difference between batch gradient descent and stochastic gradient descent?\n",
        "\n",
        "bgd updates once after passing through the entire dataset whereas sgd sees only one row.\n",
        "\n",
        "stochastic gradient descent also thus adds noise due to the randomness and hence is most suited for non-convex functions unlike bgd.\n",
        "\n",
        "also sgd is computaionlly less heavy memory and time wise"
      ],
      "metadata": {
        "id": "lULwVmTdyTUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "import numpy as np\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "yks54xOwW5Kb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = load_diabetes(return_X_y = True)"
      ],
      "metadata": {
        "id": "eh3Lio3KRq0y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=2)"
      ],
      "metadata": {
        "id": "YPgahokXR10q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FCNBs6tBOvM1"
      },
      "outputs": [],
      "source": [
        "class SGDregressor:\n",
        "  def __init__(self,learning_rate,epochs):\n",
        "    self.intercept_ = None\n",
        "    self.coef_ = None\n",
        "    self.lr = learning_rate\n",
        "    self.epochs = epochs\n",
        "\n",
        "  def fit(self,X_train,y_train):\n",
        "    self.intercept_ = 0\n",
        "    self.coef_ = np.ones(X_train.shape[1])\n",
        "\n",
        "    for i in range(self.epochs):\n",
        "      for j in range(X_train.shape[0]): #for every row\n",
        "        idx = np.random.randint(0,X_train.shape[0]) #generates a random integer\n",
        "        y_hat = np.dot(X_train[idx],self.coef_) + self.intercept_ #this is number not a matrix\n",
        "\n",
        "        intercept_der = -2*(y_train[idx]-y_hat)\n",
        "        self.intercept_ = self.intercept_ - (self.lr*intercept_der)\n",
        "\n",
        "        ceof_der = -2*np.dot((y_train[idx]-y_hat),X_train[idx])\n",
        "        self.coef_ = self.coef_ - (self.lr*ceof_der)\n",
        "    print(self.intercept_,self.coef_)\n",
        "\n",
        "  def predict(self,X_test):\n",
        "    return np.dot(X_test,self.coef_) + self.intercept_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = SGDregressor(0.1,100)"
      ],
      "metadata": {
        "id": "qGfNWvAEZfsG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7K6U2j3Zmfe",
        "outputId": "74cb5591-9e67-466c-f6c7-a4a36ad6aa55"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "149.9521589461805 [ -12.89866829 -158.91879823  530.39578132  350.75164889 -145.91524254\n",
            "  -47.04080022 -187.55814337   19.61602028  584.54976157   26.95357913]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = sgd.predict(X_test)"
      ],
      "metadata": {
        "id": "HdbSydwvbhrc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLHR2ZW9bmMi",
        "outputId": "68bf967b-dbef-47ef-de16-07367d7af170"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.433309365329151"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rpFAxwp8bt7J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}